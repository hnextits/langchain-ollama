{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41ce62a8-251f-4f9e-b375-e93a5861c3fe",
   "metadata": {},
   "source": [
    "# RAG 기초"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9c7374",
   "metadata": {},
   "source": [
    "## Enviornment (.env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76f68a8-4745-4377-8057-6090b87377d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .env 파일을 불러옵니다.\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e67655",
   "metadata": {},
   "source": [
    "## Tool 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9df40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplies a and b.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "tools = [add, multiply]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e60bd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "# Note that the docstrings here are crucial, as they will be passed along\n",
    "# to the model along with the class name.\n",
    "class Add(BaseModel):\n",
    "    \"\"\"Add two integers together.\"\"\"\n",
    "\n",
    "    a: int = Field(..., description=\"First integer\")\n",
    "    b: int = Field(..., description=\"Second integer\")\n",
    "\n",
    "\n",
    "class Multiply(BaseModel):\n",
    "    \"\"\"Multiply two integers together.\"\"\"\n",
    "\n",
    "    a: int = Field(..., description=\"First integer\")\n",
    "    b: int = Field(..., description=\"Second integer\")\n",
    "\n",
    "\n",
    "tools = [Add, Multiply]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a45abc",
   "metadata": {},
   "source": [
    "## Tool Calling / Function Calling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf277aa0",
   "metadata": {},
   "source": [
    "\n",
    "### 1) OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a446bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm_with_tools = llm.bind_tools(tools=[add, multiply])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a68204b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is 3 * 12? Also, what is 11 + 49?\"\n",
    "\n",
    "response = llm_with_tools.invoke(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b789eaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d35e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools(tools=[Add, Multiply])\n",
    "response = llm_with_tools.invoke(query)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdb543f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568b8480",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, ToolMessage\n",
    "\n",
    "messages = [HumanMessage(query)]\n",
    "ai_msg = llm_with_tools.invoke(messages)\n",
    "messages.append(ai_msg)\n",
    "for tool_call in ai_msg.tool_calls:\n",
    "    selected_tool = {\"add\": add, \"multiply\": multiply}[tool_call[\"name\"].lower()]\n",
    "    tool_output = selected_tool.invoke(tool_call[\"args\"])\n",
    "    messages.append(ToolMessage(tool_output, tool_call_id=tool_call[\"id\"]))\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff4dd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c39c627",
   "metadata": {},
   "source": [
    "### 2) Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a121e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
    "\n",
    "llm = OllamaFunctions(model=\"llama3\", format=\"json\")\n",
    "llm_with_tools = llm.bind_tools(tools=[Add, Multiply])\n",
    "\n",
    "# query = \"What is 3 * 12? Also, what is 11 + 49?\"\n",
    "query = \"what is 11 + 49? Also, What is 3 * 12?\"\n",
    "response = llm_with_tools.invoke(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329ae3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbd3c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, FunctionMessage\n",
    "\n",
    "# messages = [HumanMessage(query)]\n",
    "messages = []\n",
    "ai_msg = llm_with_tools.invoke(query)\n",
    "messages.append(ai_msg)\n",
    "for tool_call in ai_msg.tool_calls:\n",
    "    selected_tool = {\"add\": add, \"multiply\": multiply}[tool_call[\"name\"].lower()]\n",
    "    tool_output = selected_tool.invoke(tool_call[\"args\"])\n",
    "    messages.append(FunctionMessage(tool_output, name=tool_call[\"name\"]))\n",
    "    \n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1686a739",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "Ollama(model=\"llama3\").invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7142521",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91765afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_template(\"\"\"Breifely answer the question based on the following operation results:\n",
    "                                               {context}\n",
    "                                               \n",
    "                                               Question:{question}\n",
    "                                               Answer:\"\"\")\n",
    "chat_model = ChatOllama(model=\"llama3\")\n",
    "llm_chain = chat_prompt | chat_model| StrOutputParser()\n",
    "llm_chain.invoke({\"context\":messages, \"question\":query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5e306e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_query(query):\n",
    "    messages = []\n",
    "    ai_msg = llm_with_tools.invoke(query)\n",
    "    messages.append(ai_msg)\n",
    "    for tool_call in ai_msg.tool_calls:\n",
    "        selected_tool = {\"add\": add, \"multiply\": multiply}[tool_call[\"name\"].lower()]\n",
    "        tool_output = selected_tool.invoke(tool_call[\"args\"])\n",
    "        messages.append(FunctionMessage(tool_output, name=tool_call[\"name\"]))   \n",
    "\n",
    "    chat_prompt = ChatPromptTemplate.from_template(\"\"\"다음 계산에 근거하여 질문에 간단히 한국어로 답하세요:\n",
    "                                                {context}\n",
    "                                                \n",
    "                                                Question:{question}\n",
    "                                                Answer:\"\"\")\n",
    "    chat_model = ChatOllama(model=\"llama3\")\n",
    "    llm_chain = chat_prompt | chat_model| StrOutputParser()\n",
    "    response = llm_chain.invoke({\"context\":messages, \"question\":query})\n",
    "    if response:\n",
    "        return response\n",
    "    else:\n",
    "        return \"No response found.\"\n",
    "\n",
    "query = \"23 더하기 17은 얼마입니까?\"\n",
    "process_query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3208ca",
   "metadata": {},
   "source": [
    "## Structured Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed20ed79",
   "metadata": {},
   "source": [
    "#### 1) (pydantic) Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64101cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class Car(BaseModel):\n",
    "    \"\"\"Information about a car.\"\"\"\n",
    "    make: Optional[str] = Field(default=None, description=\"The make of the car\")\n",
    "    model_name: Optional[str] = Field(default=None, description=\"The model name of the car\")\n",
    "    model_year: Optional[int] = Field(\n",
    "        default=None, description=\"The year the car model was manufactured\"\n",
    "    )\n",
    "    color: Optional[str] = Field(default=None, description=\"The color of the car\")\n",
    "    price: Optional[float] = Field(default=None, description=\"The price of the car\")\n",
    "    mileage: Optional[float] = Field(default=None, description=\"The mileage of the car\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594015b6",
   "metadata": {},
   "source": [
    "#### 2) Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e7f48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an expert extraction algorithm. \"\n",
    "            \"Only extract relevant information from the text. \"\n",
    "            \"If you do not know the value of an attribute asked to extract, \"\n",
    "            \"return null for the attribute's value.\",\n",
    "        ),\n",
    "        (\"human\", \"{text}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28a2fbe",
   "metadata": {},
   "source": [
    "#### 3) OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087b7b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "runnable = prompt | llm.with_structured_output(schema=Car)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a99eb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "현재 환경부와 산업통상자원부가 심사 중인 BYD의 소형 해치백 차량인 ‘돌핀’과 중형 세단 차량인 ‘씰’의 중국 내 최저 판매 가격은 각각 1900만 원, 3900만 원이다. 특히 돌핀은 국내에서 가장 값싼 경형 전기차인 ‘기아 레이EV(세제 혜택 전 2775만 원)’와 비교해도 압도적으로 저렴하다.\n",
    "씰은 BYD의 셀투보디(CTB) 기술이 세계 최초로 적용된 차량으로 가격 대비 높은 성능을 자랑한다. CTB란 차량 본체와 배터리·배터리관리시스템(BMS) 등을 하나로 통합해 강성과 효율성을 모두 높이는 기술을 뜻한다. 두 차량 모두 유럽의 신차 안정성 프로그램(euro NCAP)에서 최고 등급을 받기도 했다.\n",
    "한국 시장 진입을 위해 BYD가 현지 판매가와 유사한 수준으로 가격을 책정할 가능성도 있다. 통상 국내 시장 진입 시 가격을 더 높여잡는 게 일반적이지만 중국산 제품에 대한 한국의 부정적 인식을 고려해 가격 경쟁력을 최우선적으로 확보할 수 있다는 것이다. 스위스 투자은행(IB) UBS에 따르면 BYD는 배터리, 차량용 반도체, 소프트웨어 등 전체 부품 75%에 대한 수직 계열화를 이루면서 경쟁사 대비 30% 수준의 가격 우위를 확보하고 있다. 아울러 리튬·인산·철(LFP) 배터리에 대한 환경부의 불리한 규정에도 일정 수준의 보조금 확보도 가능하다. 현재 돌핀과 씰의 판매 가격은 국내 전기차 보조금 전액 지원 기준인 5500만 원을 충족한다. 유럽 인증 기준을 만족시키는 최대 427㎞(돌핀), 570㎞(씰)에 이르는 1회 충전 주행거리도 유리한 요소다.\n",
    "BYD의 대항마로는 최근 기아가 출시한 소형 스포츠유틸리티차량(SUV) ‘EV3’가 꼽힌다. EV3는 니켈·코발트·망간(NCM) 배터리를 탑재해 롱레인지 모델 기준 1회 충전에 501㎞ 주행거리를 확보했다. 가격은 보조금 적용 시 3000만 원 중반대로 전기차 대중화라는 목표를 이루기 위한 기아의 주력 모델이다. KG모빌리티의 코란도EV(3000만 원대)도 BYD의 경쟁 상대다.\n",
    "\"\"\"\n",
    "response = runnable.invoke({\"text\": text})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef1ccd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "class Data(BaseModel):\n",
    "    \"\"\"Extracted data about cars.\"\"\"\n",
    "    cars: List[Car] = Field(\n",
    "        default=None, description=\"Extracted information about cars\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69c8e43",
   "metadata": {},
   "source": [
    "#### 4) 여러 개의 Entity 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e83c1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "class Data(BaseModel):\n",
    "    \"\"\"Extracted data about cars.\"\"\"\n",
    "    cars: List[Car] = Field(\n",
    "        default=None, description=\"Extracted information about cars\"\n",
    "    )\n",
    "\n",
    "runnable = prompt | llm.with_structured_output(schema=Data)\n",
    "response = runnable.invoke({\"text\": text})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21e928d",
   "metadata": {},
   "source": [
    "### 5) Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc53e256",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"<|start_header_id|>system<|end_header_id|>\n",
    "You are an expert extraction algorithm. Only extract relevant information from the text.\n",
    "If you do not know the value of an attribute asked to extract, return null for the attribute's value.\n",
    "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "TEXT: {context}\n",
    "QUESTION: {question}\n",
    "JSON:\n",
    "<|eot_id|>\n",
    "<|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "llm = OllamaFunctions(model=\"llama3\", format=\"json\", temperature=0)\n",
    "chain = prompt | llm.with_structured_output(schema=Car)\n",
    "response = chain .invoke({\"context\": text, \"question\": \"Describe 코란도\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43244c7",
   "metadata": {},
   "source": [
    "## API 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9db475",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class Stock(BaseModel):\n",
    "    \"\"\"Trading Stock\"\"\"\n",
    "\n",
    "    ticker: Optional[str] = Field(default=None, description=\"\"\"The ticker of the stock (\"005930\", \"AAPL\", ...)\"\"\")\n",
    "    start_date: Optional[str] = Field(default=None, description=\"\"\"The start trading date (\"2021-01-01\", ...)\"\"\")\n",
    "    end_date: Optional[str] = Field(default=None, description=\"\"\"The end trading date (\"2021-12-31\", ...)\"\"\")\n",
    "\n",
    "class Market(BaseModel):\n",
    "    \"\"\"Stock market index\"\"\"\n",
    "\n",
    "    ticker: Optional[str] = Field(default=None, description=\"\"\"The ticker of the market index based on the following list(KS11, VIX, ...):\n",
    "        - KS11: KOSPI 지수, 코스피 지수\n",
    "        - KQ11: KOSDAQ 지수, 코스닥 지수\n",
    "        - KS200: KOSPI 200, 코스피 200\n",
    "        - DJI: 다우존스 지수, Dow Jones Industrial Average\n",
    "        - IXIC: 나스닥 종합지수, NASDAQ Composite\n",
    "        - S&P500: S&P500 지수, NYSE\n",
    "        - RUT: 러셀2000 지수, Russell 2000\n",
    "        - VIX: VIX 지수, CBOE Volatility Index\n",
    "        - SSEC: 상해 종합지수, Shanghai Composite\n",
    "        - HSI: 항셍지수, Hang Seng\n",
    "        - N225: 일본 닛케이지수, Nikkei 225\n",
    "        - FTSE: 영국 FTSE100, FTSE 100\n",
    "        - FCHI: 프랑스 CAC40 지수, CAC 40\n",
    "        - GDAXI: 독일 닥스지수, DAX 30\"\"\")\n",
    "    start_date: Optional[str] = Field(default=None, description=\"\"\"The start trading date (\"2021-01-01\", ...)\"\"\")\n",
    "    end_date: Optional[str] = Field(default=None, description=\"\"\"The end trading date (\"2021-12-31\", ...)\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6b3c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
    "\n",
    "llm = OllamaFunctions(model=\"llama3\", format=\"json\")\n",
    "llm_with_tools = llm.bind_tools(tools=[Stock, Market])\n",
    "\n",
    "query = \"삼성전자의 2023년 주가\"\n",
    "\n",
    "response = llm_with_tools.invoke(query)\n",
    "print(response.tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ef6720",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"2024년 3월 테슬라\"\n",
    "\n",
    "response = llm_with_tools.invoke(query)\n",
    "print(response.tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003fad9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"2022년 나스닥 지수\"\n",
    "\n",
    "response = llm_with_tools.invoke(query)\n",
    "print(response.tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c47563",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"코스닥 지수 2019년 7월\"\n",
    "\n",
    "response = llm_with_tools.invoke(query)\n",
    "print(response.tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e752e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### FinanceDataReader\n",
    "import FinanceDataReader as fdr\n",
    "\n",
    "df = fdr.DataReader(\"KQ11\", \"2019-07-01\", \"2019-07-31\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920b7b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"2022년 3월 1일부터 2022년 3월 15일까지 삼성전자 주가\"\n",
    "\n",
    "ai_msg = llm_with_tools.invoke(query)\n",
    "ticker = ai_msg.tool_calls[0]['args']['ticker']\n",
    "start_date = ai_msg.tool_calls[0]['args']['start_date']\n",
    "end_date = ai_msg.tool_calls[0]['args']['end_date']\n",
    "\n",
    "print(ticker, start_date, end_date)\n",
    "df = fdr.DataReader(ticker, start_date, end_date)\n",
    "df.head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7127af7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
