{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q langchain langchain-openai google-search-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = 'OPENAI_API_KEY'\n",
    "os.environ['SERPAPI_API_KEY'] = 'SERPAPI_API_KEY'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News 데이터 수집 - SerpAPI 활용\n",
    "- 인증키 발급 필요 (월 100회 무료)\n",
    "- https://serpapi.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import SerpAPIWrapper\n",
    "\n",
    "params = {\n",
    "    \"engine\": \"google_news\",\n",
    "    \"gl\": \"KR\",\n",
    "    \"hl\": \"ko\",\n",
    "}\n",
    "search = SerpAPIWrapper(params=params)\n",
    "\n",
    "search.run(\"이차전지 산업\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = search.run(\"이차전지 산업\")\n",
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = results[0]['link']\n",
    "url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangChain WebBaseLoader 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader - 웹페이지 데이터 가져오기\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(url)\n",
    "docs = loader.load()\n",
    "\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 뉴스기사에서 본문 텍스트를 추출하는 함수\n",
    "def extract_longest_text(text):\n",
    "    # 개행문자(\\n\\n)를 기준으로 텍스트를 분할\n",
    "    segments = text.split('\\n')\n",
    "    # 가장 긴 텍스트 조각을 찾음\n",
    "    longest_segment = max(segments, key=len)\n",
    "    return longest_segment\n",
    "\n",
    "text = docs[0].page_content\n",
    "\n",
    "longest_text = extract_longest_text(text)\n",
    "print(\"가장 긴 텍스트:\\n\", longest_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SerpAPI 검색 결과를 순회하면서 본문 텍스트를 추출하여 기존 딕셔너리에 추가\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "new_results = []\n",
    "for result in tqdm(results):\n",
    "    try:\n",
    "        url = result['link']\n",
    "        loader = WebBaseLoader(url)\n",
    "        docs = loader.load()\n",
    "        text = docs[0].page_content\n",
    "        longest_text = extract_longest_text(text)\n",
    "        result['content'] = longest_text\n",
    "        new_results.append(result)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "# 결과 확인\n",
    "print(\"새로운 결과 개수:\", len(new_results))\n",
    "new_results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 판다스 데이터프레임으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.DataFrame(new_results)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 뉴스 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# prompt\n",
    "prompt_template = \"\"\"Write a concise summary of the following in Korean Hangul (한글):\n",
    "\"{text}\"\n",
    "CONCISE SUMMARY:\"\"\"\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "# LLM\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "# output parser\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# Chain\n",
    "llm_chain = prompt | llm | output_parser\n",
    "\n",
    "response = llm_chain.invoke({\"text\": data['content'][0]})\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 뉴스 본문을 입력으로 사용하여 요약 결과를 생성하는 함수\n",
    "def summarize_news(content):\n",
    "    response = llm_chain.invoke({\"text\": content})\n",
    "    return response\n",
    "\n",
    "# 결과 확인 - 테스트를 위해서 첫 3행만 별도로 추출하여 요약\n",
    "df_test = data.head(3)\n",
    "df_test['summary'] = df_test['content'].apply(summarize_news)\n",
    "\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[['content', 'summary']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 키워드 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# prompt\n",
    "prompt_template = \"\"\"Please extract 3 key words from the following content in Korean Hangul (한글) and separate them with commas (,):\n",
    "\"{text}\"\n",
    "Key words:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "# LLM\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "# output parser\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# Chain\n",
    "llm_chain = prompt | llm | output_parser\n",
    "\n",
    "response = llm_chain.invoke({\"text\": data['content'][0]})\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 뉴스 본문을 입력으로 사용하여 핵심 키워드를 추출하는 함수\n",
    "def extract_keywords(content):\n",
    "    response = llm_chain.invoke({\"text\": content})\n",
    "    return response\n",
    "\n",
    "# 결과 확인 - 테스트를 위해서 첫 3행만 별도로 추출하여 추출\n",
    "df_test['keywords'] = df_test['content'].apply(extract_keywords)\n",
    "\n",
    "df_test[['content', 'summary', 'keywords']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 뉴스 카테고리 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# prompt\n",
    "prompt_template = \"\"\"Based on the following content, please classify the news into the appropriate category and provide the category name in Korean Hangul (한글):\n",
    "\"{text}\"\n",
    "News Category:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "# LLM\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "# output parser\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# Chain\n",
    "llm_chain = prompt | llm | output_parser\n",
    "\n",
    "response = llm_chain.invoke({\"text\": data['content'][0]})\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 뉴스 본문을 입력으로 사용하여 카테고리를 분류하는 함수\n",
    "def classify_news_category(content):\n",
    "    response = llm_chain.invoke({\"text\": content})\n",
    "    return response\n",
    "\n",
    "# 결과 확인 - 테스트를 위해서 첫 3행만 별도로 추출하여 카테고리 분류\n",
    "df_test['category'] = df_test['content'].apply(classify_news_category)\n",
    "\n",
    "df_test[['content', 'summary', 'keywords', 'category']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 키워드에서 한글만 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "korean_word = re.findall(r'[가-힣]+', df_test['category'][0])[0]\n",
    "korean_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 람다 함수를 사용하여 카테고리에서 한글 단어만 추출 \n",
    "df_test['category'].apply(lambda x: re.findall(r'[가-힣]+', x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['category'] = df_test['category'].apply(lambda x: re.findall(r'[가-힣]+', x)[0])\n",
    "df_test[['content', 'summary', 'keywords', 'category']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
